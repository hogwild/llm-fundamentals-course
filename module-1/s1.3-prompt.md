# Session 1.3: From N-grams to Neural Representations

## Primary Question
How can neural approaches represent words as mathematical objects that capture meaning, addressing the fundamental limitations of n-gram models?

Through exploring vector representations and neural network basics, you'll discover how language can be transformed into forms that machines can process to find deeper patterns than simple word counting.

## Knowledge Points Overview
This session covers the following key knowledge points:
1. Contextual word meaning and n-gram limitations revisited
2. Words as vectors: The fundamental shift
3. Neural network basics for language processing
4. Input representation in neural language models

---

## Knowledge Point 1: Contextual Word Meaning and N-gram Limitations Revisited

**Probing Question**: What specific limitations of n-gram models prevent them from capturing the meaning of words in different contexts?

### Beyond Statistical Counting
- **Interactive Activity**: Analyze these sentences:
  * "The bank is by the river."
  * "I deposited money in the bank."
  * "The bank approved my loan."
  
- **Discussion Points**:
  * Why do traditional n-grams struggle with word sense disambiguation?
  * How does the sparsity problem from Session 1.2 affect understanding word meaning?
  * What would a meaningful representation of words need to capture?

- **Core Limitation**: N-grams treat words as discrete symbols without inherent meaning
  * Words are either identical or completely different
  * No concept of similarity or relatedness
  * No way to generalize across similar contexts

- **Visual Reference**: Examine Figure 1 from "Statistical Language Models Based on Neural Networks" (Mikolov, 2012, PhD Thesis) showing the discrete nature of traditional language models.

### Understanding Check ✓
- What are two fundamental limitations of n-gram models when dealing with word meaning?
- Why is the discrete representation of words problematic for language understanding?
- How do these limitations connect to the sparsity problem we encountered in Session 1.2?

**Navigation Options**:
1. Proceed to Knowledge Point 2
2. Explore more examples of context-dependent meanings
3. See visualization of the limitations of discrete representations
4. Request practice exercises

---

## Knowledge Point 2: Words as Vectors: The Fundamental Shift

**Probing Question**: What if words could be represented as points in a multidimensional space, where similar words are closer together?

### The Vector Representation Revolution
- **Conceptual Foundation**:
  * What is a vector? (introduction to this mathematical concept)
  * Vectors as positions in a space with multiple dimensions
  * Similarity as distance between points in this space

- **Key Insight**: Words as continuous vectors instead of discrete symbols
  * Each word = a list of numbers (e.g., [0.2, -0.5, 0.7, ...])
  * Each number (dimension) potentially capturing a feature of meaning
  * Similar words have similar vectors (closer in space)

- **Interactive Exploration**: Try visualizing simple 2D word vectors
  * Example: "king" = [0.9, 0.1], "queen" = [0.8, 0.3], "man" = [0.7, -0.2]
  * Plot these on a 2D graph
  * Observe relationships between points

- **Visual Reference**: Examine word embedding visualization from "The Illustrated Word2Vec" (Alammar, 2019, https://jalammar.github.io/illustrated-word2vec/) showing words in 2D space.

### Understanding Check ✓
- What is a word vector, in your own words?
- How does representing words as vectors differ fundamentally from n-gram approaches?
- Why might vector representations better capture word meaning and relationships?

**Navigation Options**:
1. Proceed to Knowledge Point 3
2. Explore more about vector representations
3. See visualization of word vectors in 2D and 3D space
4. Request practice exercises

---

## Knowledge Point 3: Neural Network Basics for Language Processing

**Probing Question**: What are neural networks, and how can they help us process language in ways that overcome n-gram limitations?

### Introduction to Neural Networks
- **Key Concept**: Artificial neurons as basic processing units
  * Inputs, weights, activation function, output
  * Simple mathematical operations (multiplication, addition, non-linear function)
  * Inspired by but simplified from biological neurons

- **From Single Neurons to Networks**:
  * Layers of neurons working together
  * Input layer, hidden layer(s), output layer
  * Information flows forward through the network

- **Why Neural Networks for Language**:
  * Ability to learn patterns from data
  * Can process continuous (vector) representations
  * Can model complex, non-linear relationships

- **Interactive Tool**: Explore a simple neural network with the "TensorFlow Playground" tool (https://playground.tensorflow.org/)

- **Visual Reference**: Examine the diagram of a simple neural network architecture from "Neural Network Methods for Natural Language Processing" (Goldberg, 2017, Morgan & Claypool Publishers).

### Understanding Check ✓
- What is an artificial neuron and how does it process information?
- Why are neural networks better suited than simple statistical methods for processing word vectors?
- How do multiple layers in a neural network help with capturing complex patterns?

**Navigation Options**:
1. Proceed to Knowledge Point 4
2. Explore neural network components in more detail
3. See interactive neural network demonstration
4. Request practice exercises

---

## Knowledge Point 4: Input Representation in Neural Language Models

**Probing Question**: How do we actually convert words into a form that neural networks can process?

### Preparing Words for Neural Processing
- **From Words to Numbers**:
  * Vocabulary creation (mapping words to indices)
  * One-hot encoding (sparse representation)
  * The need for dense representations

- **The Embedding Layer**:
  * Purpose: Convert word indices to dense vectors
  * Embedding matrix as a lookup table
  * Each row = vector representation of one word
  * Initially random, learned during training

- **Context Window Representation**:
  * Combining multiple word vectors as input
  * Fixed-size context (similar to n-grams)
  * Connection to n-gram models from Session 1.2

- **Code Example** (conceptual, not for execution):
```python
# Example of embedding lookup
vocab = {"the": 0, "cat": 1, "sat": 2, "on": 3, "mat": 4}
embedding_matrix = [
    [0.1, 0.2, 0.3],  # Vector for "the"
    [0.4, 0.5, 0.6],  # Vector for "cat"
    # ...and so on
]

# Convert "the cat sat" to vector representations
word_indices = [vocab["the"], vocab["cat"], vocab["sat"]]
word_vectors = [embedding_matrix[idx] for idx in word_indices]
```

- **Visual Reference**: Examine Figure 1 from "A Neural Probabilistic Language Model" (Bengio et al., 2003, https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) showing the embedding lookup process.

### Understanding Check ✓
- What is the purpose of an embedding layer in a neural language model?
- How does this method of representation differ from what we used in n-gram models?
- Why do we need to convert words to vectors before neural network processing?

**Navigation Options**:
1. Proceed to Session 1.4
2. Explore input representation in more detail
3. See visualization of embedding lookup process
4. Request practice exercises

---

## Reflection and Bridge to Next Session

**Integration Activity**: Summarize the key differences between n-gram representations and neural representations of language, highlighting how the shift to vector representations addresses fundamental limitations.

**Key Questions to Consider**:
- How does the shift from discrete to continuous representation fundamentally change what's possible in language modeling?
- Why is it important for words to have "relationships" to each other in their representation?
- How do these new representation techniques set the stage for more advanced language models?

**Next Steps Preview**: In Session 1.4, we'll explore how neural language models actually make predictions and learn from data, building on the representation techniques covered here.

---

## Additional Resources

### Visualizations
- Word vector spaces in 2D and 3D
- Neural network architecture diagrams
- Embedding lookup process illustrations

### Interactive Tools
- TensorFlow Embedding Projector (https://projector.tensorflow.org/) - Interactive exploration of word embeddings
- TensorFlow Playground for neural networks (https://playground.tensorflow.org/) - Visual neural network experimentation
- Interactive Word2Vec Visualization (WEVI) (https://ronxin.github.io/wevi/) - Step-by-step visualization of Word2Vec training

### Research References
- Bengio, Y., et al. (2003). "A Neural Probabilistic Language Model." Journal of Machine Learning Research, 3, 1137-1155. https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf
- Mikolov, T. (2012). "Statistical Language Models Based on Neural Networks." PhD Thesis, Brno University of Technology.
- Mikolov, T., et al. (2013). "Efficient Estimation of Word Representations in Vector Space." ICLR Workshop. https://arxiv.org/abs/1301.3781
- Goldberg, Y. (2017). "Neural Network Methods for Natural Language Processing." Morgan & Claypool Publishers.
- Alammar, J. (2019). "The Illustrated Word2Vec." https://jalammar.github.io/illustrated-word2vec/
