# LLM Fundamentals: A Progressive Learning Series

This repository contains materials for a flipped classroom discussion series on Large Language Models (LLMs), designed for non-CS/AI students, researchers, and professors. The goal is to build a fundamental understanding of LLMs through guided exploration and structured discussions.

## Course Philosophy

This series takes a unique approach:
- **Principle-focused**: Understanding the core concepts behind LLM behavior without diving into technical details
- **Progressive learning**: Questions build systematically on previous concepts
- **Flipped classroom**: Self-directed exploration before group discussions
- **Accessible**: Designed specifically for those without CS/AI backgrounds

## Learning Structure

1. Students select questions from the Progressive Question Framework
2. Self-learning occurs through conversations with AI tools, reading papers, etc.
3. In-class discussions focus on connecting concepts and addressing misconceptions
4. Reflection and evaluation help track understanding using our rubric

## Module Overview

### Module 1: Foundations of Word Prediction and Embeddings
This module introduces the core concepts of language modeling through the lens of next-word prediction, starting with simple n-gram models and progressing to neural word embeddings.

**Key Concepts:**
- Next-token prediction as the foundational mechanism
- N-gram models and their limitations
- Supervised learning approaches (Bengio's neural language model)
- Unsupervised learning with Word2Vec
- Tokens vs. words in language processing
- Embeddings and their role in representing meaning

### Module 2: Transformer Architecture and LLM Training
This module examines the transformer architecture that powers modern LLMs, focusing on how these models are pre-trained and fine-tuned to follow instructions.

**Key Concepts:**
- Attention mechanisms and self-attention
- Feed-forward networks as computational engines
- Transformer architecture components
- Pre-training objectives and techniques
- Instruction following and prompt engineering
- Scaling properties of transformer models

### Module 3: Reasoning and Alignment in Large Models
This module explores advanced capabilities of modern LLMs, particularly their reasoning abilities and how they're aligned with human values and intentions.

**Key Concepts:**
- Fundamentals of Reinforcement Learning
- Reinforcement Learning from Human Feedback (RLHF)
- Value alignment techniques
- Policy gradient methods for improving reasoning
- Chain-of-thought and step-by-step reasoning
- Test-time computation and dynamic reasoning strategies

## Getting Started

Begin with Module 1 and explore the questions in order. Each module contains:
- Key learning objectives
- Suggested exploration questions
- Reading materials
- Discussion prompts

## Evaluation Framework

Student understanding is evaluated across five dimensions:
1. Question Decomposition
2. Critical Thinking
3. Connection-Making
4. Conceptual Understanding
5. Reflection Quality

## Contributing

This is an educational project designed to evolve with our understanding of LLMs. Contributions, suggestions, and feedback are welcome.
